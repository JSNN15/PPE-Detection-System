{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 01 - Preparaci√≥n de Dataset para Detecci√≥n de EPP\n",
    "\n",
    "Este notebook gu√≠a el proceso de preparaci√≥n del dataset para entrenar modelos de detecci√≥n de EPP.\n",
    "\n",
    "## Objetivos:\n",
    "- Recolectar y organizar im√°genes de entorno industrial\n",
    "- Anotar EPPs usando herramientas como Roboflow, LabelImg o CVAT\n",
    "- Preparar dataset en formato YOLO y Azure Custom Vision\n",
    "- Realizar data augmentation para mejorar robustez\n",
    "\n",
    "## EPPs a Detectar:\n",
    "1. **Gafas de seguridad** (obligatorio)\n",
    "2. **Zapatos de seguridad** (obligatorio)\n",
    "3. **Traje/overol verde o cotona blanca/azul** (obligatorio)\n",
    "4. **Mascarilla/respirador qu√≠mico** (condicional)\n",
    "5. **Guantes resistentes a qu√≠micos** (condicional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instalaci√≥n de dependencias\n",
    "!pip install roboflow pillow opencv-python albumentations pandas matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import yaml\n",
    "from pathlib import Path\n",
    "import shutil\n",
    "from PIL import Image\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Cargar variables de entorno\n",
    "load_dotenv('../.env')\n",
    "\n",
    "# Configuraci√≥n\n",
    "PROJECT_ROOT = Path('..').resolve()\n",
    "DATA_DIR = PROJECT_ROOT / 'data'\n",
    "RAW_DIR = DATA_DIR / 'raw'\n",
    "PROCESSED_DIR = DATA_DIR / 'processed'\n",
    "MODELS_DIR = DATA_DIR / 'models'\n",
    "\n",
    "# Crear directorios\n",
    "for dir_path in [RAW_DIR, PROCESSED_DIR, MODELS_DIR]:\n",
    "    dir_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(f\"Directorios creados en: {DATA_DIR}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Paso 1: Fuentes de Datos\n",
    "\n",
    "### Opci√≥n A: Dataset P√∫blico (Inicial)\n",
    "Puedes empezar con datasets p√∫blicos de PPE/EPP:\n",
    "- Roboflow Universe: https://universe.roboflow.com/search?q=ppe\n",
    "- Dataset de Kaggle sobre PPE detection\n",
    "- Open Images Dataset (con filtros de seguridad industrial)\n",
    "\n",
    "### Opci√≥n B: Dataset Personalizado (Recomendado para producci√≥n)\n",
    "Captura im√°genes de TU planta de lixiviaci√≥n:\n",
    "1. Toma 500-1000 fotos del entorno real\n",
    "2. Incluye variaciones: diferentes √°ngulos, iluminaci√≥n, personas\n",
    "3. Captura casos positivos (con EPP) y negativos (sin EPP)\n",
    "4. Incluye los colores espec√≠ficos: overol verde, cotona blanca/azul"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Opci√≥n A: Descargar dataset de Roboflow\n",
    "from roboflow import Roboflow\n",
    "\n",
    "ROBOFLOW_API_KEY = os.getenv('ROBOFLOW_API_KEY')\n",
    "\n",
    "if ROBOFLOW_API_KEY:\n",
    "    rf = Roboflow(api_key=ROBOFLOW_API_KEY)\n",
    "    \n",
    "    # Ejemplo: descargar dataset p√∫blico de PPE\n",
    "    # Busca en https://universe.roboflow.com un dataset de PPE que te guste\n",
    "    # project = rf.workspace(\"workspace-name\").project(\"project-name\")\n",
    "    # dataset = project.version(1).download(\"yolov8\", location=str(RAW_DIR))\n",
    "    \n",
    "    print(\"Configura tu proyecto de Roboflow para descargar dataset\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è ROBOFLOW_API_KEY no configurada. A√±√°dela al archivo .env\")\n",
    "    print(\"Puedes obtener una API key gratuita en: https://roboflow.com\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Paso 2: Estructura del Dataset\n",
    "\n",
    "Organizaremos el dataset en formato est√°ndar para YOLO y Azure:\n",
    "\n",
    "```\n",
    "data/\n",
    "‚îú‚îÄ‚îÄ raw/                  # Datos originales sin procesar\n",
    "‚îú‚îÄ‚îÄ processed/\n",
    "‚îÇ   ‚îú‚îÄ‚îÄ yolo/            # Formato YOLO (para open source)\n",
    "‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ images/\n",
    "‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ train/\n",
    "‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ val/\n",
    "‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ test/\n",
    "‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ labels/\n",
    "‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ train/\n",
    "‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ val/\n",
    "‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ test/\n",
    "‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ data.yaml\n",
    "‚îÇ   ‚îî‚îÄ‚îÄ azure/           # Formato Azure Custom Vision\n",
    "‚îÇ       ‚îú‚îÄ‚îÄ images/\n",
    "‚îÇ       ‚îî‚îÄ‚îÄ annotations.csv\n",
    "‚îî‚îÄ‚îÄ models/              # Modelos entrenados\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear estructura de directorios\n",
    "YOLO_DIR = PROCESSED_DIR / 'yolo'\n",
    "AZURE_DIR = PROCESSED_DIR / 'azure'\n",
    "\n",
    "for split in ['train', 'val', 'test']:\n",
    "    (YOLO_DIR / 'images' / split).mkdir(parents=True, exist_ok=True)\n",
    "    (YOLO_DIR / 'labels' / split).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "(AZURE_DIR / 'images').mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(\"‚úÖ Estructura de directorios creada\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Paso 3: Clases de EPP\n",
    "\n",
    "Definimos las clases que detectar√° nuestro modelo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definici√≥n de clases\n",
    "PPE_CLASSES = {\n",
    "    0: 'safety_glasses',      # Gafas de seguridad\n",
    "    1: 'safety_shoes',         # Zapatos de seguridad\n",
    "    2: 'green_coverall',       # Overol verde\n",
    "    3: 'white_coat',           # Cotona blanca\n",
    "    4: 'blue_coat',            # Cotona azul\n",
    "    5: 'chemical_mask',        # Mascarilla qu√≠mica\n",
    "    6: 'chemical_gloves',      # Guantes qu√≠micos\n",
    "    7: 'person_no_ppe',        # Persona sin EPP (para detecci√≥n negativa)\n",
    "}\n",
    "\n",
    "# Crear archivo data.yaml para YOLO\n",
    "data_yaml = {\n",
    "    'path': str(YOLO_DIR.absolute()),\n",
    "    'train': 'images/train',\n",
    "    'val': 'images/val',\n",
    "    'test': 'images/test',\n",
    "    'nc': len(PPE_CLASSES),  # n√∫mero de clases\n",
    "    'names': list(PPE_CLASSES.values())\n",
    "}\n",
    "\n",
    "with open(YOLO_DIR / 'data.yaml', 'w') as f:\n",
    "    yaml.dump(data_yaml, f, default_flow_style=False)\n",
    "\n",
    "print(\"‚úÖ Archivo data.yaml creado\")\n",
    "print(f\"Clases: {list(PPE_CLASSES.values())}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Paso 4: Herramientas de Anotaci√≥n\n",
    "\n",
    "Para anotar tus im√°genes personalizadas, usa una de estas herramientas:\n",
    "\n",
    "### 1. Roboflow (Recomendado - Cloud)\n",
    "- **Ventajas**: Interface intuitiva, auto-labeling con IA, augmentation autom√°tica\n",
    "- **Link**: https://roboflow.com\n",
    "- **Costo**: Plan gratuito hasta 10,000 im√°genes\n",
    "- **Export**: Directo a YOLO, Azure, etc.\n",
    "\n",
    "### 2. LabelImg (Local - Open Source)\n",
    "```bash\n",
    "pip install labelImg\n",
    "labelImg\n",
    "```\n",
    "\n",
    "### 3. CVAT (Local/Cloud - Open Source)\n",
    "- **Link**: https://cvat.org\n",
    "- **Ventajas**: Colaborativo, potente, gratis\n",
    "\n",
    "### Consejos de Anotaci√≥n:\n",
    "1. **Precisi√≥n**: Dibuja bounding boxes ajustados al EPP\n",
    "2. **Consistencia**: Usa los mismos nombres de clase siempre\n",
    "3. **Casos dif√≠ciles**: Incluye oclusiones parciales, diferentes √°ngulos\n",
    "4. **Balance**: Asegura que todas las clases tengan similar cantidad de ejemplos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Paso 5: Data Augmentation\n",
    "\n",
    "Aumentar el dataset con transformaciones para mejorar la robustez del modelo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "\n",
    "# Definir transformaciones de augmentation\n",
    "transform = A.Compose([\n",
    "    A.HorizontalFlip(p=0.5),\n",
    "    A.RandomBrightnessContrast(p=0.3),\n",
    "    A.RandomGamma(p=0.3),\n",
    "    A.Blur(blur_limit=3, p=0.2),\n",
    "    A.GaussNoise(p=0.2),\n",
    "    A.ShiftScaleRotate(shift_limit=0.1, scale_limit=0.2, rotate_limit=15, p=0.5),\n",
    "    A.HueSaturationValue(p=0.3),\n",
    "], bbox_params=A.BboxParams(format='yolo', label_fields=['class_labels']))\n",
    "\n",
    "print(\"‚úÖ Pipeline de augmentation configurado\")\n",
    "print(\"Transformaciones: Flip, Brightness, Blur, Noise, Rotation, Color\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ejemplo de aplicaci√≥n de augmentation\n",
    "def augment_image(image_path, bboxes, class_labels, num_augmentations=3):\n",
    "    \"\"\"\n",
    "    Aplica data augmentation a una imagen y sus bounding boxes\n",
    "    \n",
    "    Args:\n",
    "        image_path: Ruta a la imagen original\n",
    "        bboxes: Lista de bounding boxes en formato YOLO [x_center, y_center, width, height]\n",
    "        class_labels: Lista de etiquetas de clase para cada bbox\n",
    "        num_augmentations: N√∫mero de versiones augmentadas a generar\n",
    "    \n",
    "    Returns:\n",
    "        Lista de tuplas (imagen_augmentada, bboxes_augmentados, labels)\n",
    "    \"\"\"\n",
    "    image = cv2.imread(str(image_path))\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    augmented_samples = []\n",
    "    \n",
    "    for i in range(num_augmentations):\n",
    "        transformed = transform(image=image, bboxes=bboxes, class_labels=class_labels)\n",
    "        augmented_samples.append((\n",
    "            transformed['image'],\n",
    "            transformed['bboxes'],\n",
    "            transformed['class_labels']\n",
    "        ))\n",
    "    \n",
    "    return augmented_samples\n",
    "\n",
    "# Ejemplo de uso (comentado hasta que tengas im√°genes)\n",
    "# augmented = augment_image('ruta/a/imagen.jpg', [[0.5, 0.5, 0.3, 0.4]], [0])\n",
    "print(\"‚úÖ Funci√≥n de augmentation lista\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Paso 6: An√°lisis del Dataset\n",
    "\n",
    "Una vez que tengas im√°genes anotadas, analiza la distribuci√≥n:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_dataset(labels_dir):\n",
    "    \"\"\"\n",
    "    Analiza la distribuci√≥n de clases en el dataset\n",
    "    \"\"\"\n",
    "    class_counts = {class_name: 0 for class_name in PPE_CLASSES.values()}\n",
    "    total_boxes = 0\n",
    "    \n",
    "    label_files = list(Path(labels_dir).glob('*.txt'))\n",
    "    \n",
    "    for label_file in label_files:\n",
    "        with open(label_file, 'r') as f:\n",
    "            for line in f:\n",
    "                class_id = int(line.split()[0])\n",
    "                class_name = PPE_CLASSES[class_id]\n",
    "                class_counts[class_name] += 1\n",
    "                total_boxes += 1\n",
    "    \n",
    "    # Crear DataFrame\n",
    "    df = pd.DataFrame([\n",
    "        {'Clase': k, 'Cantidad': v, 'Porcentaje': v/total_boxes*100 if total_boxes > 0 else 0}\n",
    "        for k, v in class_counts.items()\n",
    "    ])\n",
    "    \n",
    "    # Visualizar\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.bar(df['Clase'], df['Cantidad'])\n",
    "    plt.xlabel('Clase de EPP')\n",
    "    plt.ylabel('N√∫mero de instancias')\n",
    "    plt.title('Distribuci√≥n de Clases en el Dataset')\n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"\\nüìä Estad√≠sticas del Dataset:\")\n",
    "    print(df.to_string(index=False))\n",
    "    print(f\"\\nTotal de anotaciones: {total_boxes}\")\n",
    "    print(f\"Total de im√°genes: {len(label_files)}\")\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Descomentar cuando tengas labels\n",
    "# df_train = analyze_dataset(YOLO_DIR / 'labels' / 'train')\n",
    "print(\"‚úÖ Funci√≥n de an√°lisis lista\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Paso 7: Divisi√≥n Train/Val/Test\n",
    "\n",
    "Recomendaci√≥n est√°ndar: 70% train, 20% validation, 10% test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def split_dataset(images_dir, labels_dir, train_ratio=0.7, val_ratio=0.2, test_ratio=0.1):\n",
    "    \"\"\"\n",
    "    Divide el dataset en train/val/test\n",
    "    \"\"\"\n",
    "    assert abs(train_ratio + val_ratio + test_ratio - 1.0) < 1e-5, \"Las proporciones deben sumar 1\"\n",
    "    \n",
    "    # Obtener lista de im√°genes\n",
    "    image_files = list(Path(images_dir).glob('*.jpg')) + list(Path(images_dir).glob('*.png'))\n",
    "    \n",
    "    # Primera divisi√≥n: train y temp (val+test)\n",
    "    train_files, temp_files = train_test_split(\n",
    "        image_files, \n",
    "        train_size=train_ratio, \n",
    "        random_state=42\n",
    "    )\n",
    "    \n",
    "    # Segunda divisi√≥n: val y test\n",
    "    val_ratio_adjusted = val_ratio / (val_ratio + test_ratio)\n",
    "    val_files, test_files = train_test_split(\n",
    "        temp_files,\n",
    "        train_size=val_ratio_adjusted,\n",
    "        random_state=42\n",
    "    )\n",
    "    \n",
    "    print(f\"üìä Divisi√≥n del dataset:\")\n",
    "    print(f\"  Train: {len(train_files)} im√°genes ({train_ratio*100:.0f}%)\")\n",
    "    print(f\"  Val:   {len(val_files)} im√°genes ({val_ratio*100:.0f}%)\")\n",
    "    print(f\"  Test:  {len(test_files)} im√°genes ({test_ratio*100:.0f}%)\")\n",
    "    \n",
    "    return train_files, val_files, test_files\n",
    "\n",
    "# Ejemplo de uso (descomentar cuando tengas im√°genes)\n",
    "# train, val, test = split_dataset(RAW_DIR / 'images', RAW_DIR / 'labels')\n",
    "print(\"‚úÖ Funci√≥n de divisi√≥n lista\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resumen y Pr√≥ximos Pasos\n",
    "\n",
    "### ‚úÖ Has completado:\n",
    "1. Configuraci√≥n de estructura de datos\n",
    "2. Definici√≥n de clases de EPP\n",
    "3. Pipeline de data augmentation\n",
    "4. Herramientas de an√°lisis\n",
    "\n",
    "### üìù Tareas pendientes:\n",
    "1. **Recolectar/descargar im√°genes** de EPP en entorno industrial\n",
    "2. **Anotar im√°genes** usando Roboflow, LabelImg o CVAT\n",
    "3. **Aplicar augmentation** para expandir el dataset\n",
    "4. **Analizar distribuci√≥n** de clases\n",
    "5. **Dividir en train/val/test**\n",
    "\n",
    "### ‚û°Ô∏è Siguiente notebook:\n",
    "- **02_model_training_azure.ipynb**: Entrenar modelo con Azure Custom Vision\n",
    "- **03_model_training_opensource.ipynb**: Entrenar modelo con YOLOv8\n",
    "\n",
    "### üí° Recursos √∫tiles:\n",
    "- [Roboflow Universe - PPE Datasets](https://universe.roboflow.com/search?q=ppe)\n",
    "- [YOLOv8 Documentation](https://docs.ultralytics.com/)\n",
    "- [Azure Custom Vision](https://www.customvision.ai/)\n",
    "- [LabelImg Tutorial](https://github.com/heartexlabs/labelImg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guardar configuraci√≥n para pr√≥ximos notebooks\n",
    "config = {\n",
    "    'project_root': str(PROJECT_ROOT),\n",
    "    'data_dir': str(DATA_DIR),\n",
    "    'yolo_dir': str(YOLO_DIR),\n",
    "    'azure_dir': str(AZURE_DIR),\n",
    "    'classes': PPE_CLASSES,\n",
    "    'num_classes': len(PPE_CLASSES)\n",
    "}\n",
    "\n",
    "with open(DATA_DIR / 'config.yaml', 'w') as f:\n",
    "    yaml.dump(config, f)\n",
    "\n",
    "print(\"‚úÖ Configuraci√≥n guardada en data/config.yaml\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
